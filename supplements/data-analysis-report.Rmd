---
title: "Sampling Strategies in DfE"
subtitle: "Data Analysis Report"
author: "Linus Hof"
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
    collapsed: true
    code_folding: hide
    keep_md: true
---

```{r setup}
# set global chunk options
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE,
                      fig.width = 14)
```

```{r pkgs}
pacman::p_load(tidyverse,
               scico,
               latex2exp,
               stringr,
               ggpubr,
               papaja)
```

```{r data}
choices <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/choice_data.rds.bz2")
cpt <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/cpt_estimates.rds")
```

# Description

This is a comprehensive data analysis underlying the core results reported in the manuscript. <!--link document-->
The analyses comprise of the description and explanation of the sampling and choice behavior produced by the the roundwise and summary integration model and different parameter combinations, as well as their translation into the psychoeconomic functions of cumulative prospect theory (CPT).  

# Core Results

* The interplay of sampling and integration strategies can produce distinct choice patterns in decisions from experience. 

* The choice patterns depend on the structure of the choice problem.

* The choice patterns translate to characteristic shapes of CPT's value and weighting function. 

* A roundwise integration strategy can cause the as-if underweighting of rare outcomes pattern in the absence of sampling error. 

# Sampling Behavior

In this section, the numbers of sampled outcomes and the sampled relative frequencies of outcomes are reported.

## Roundwise Integration Model

The following figure displays the number of outcomes sampled within choice trials (trial-level sample sizes).
Each point represents the median across all trials for the respective parameter combination.
The dashed horizontal line represents the meta-analytic median reported by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)) for choices between a two-outcome risky prospect and a safe prospect.

```{r ggplot setup}
# define functions for assigning facet labels in facet_wrap() and facet_grid()
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = ""))
  }

label_psi <- function(string) {
  TeX(paste("$\\psi=$", string, sep = "")) #switching probability parameter psi
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}
```

```{r trial-level sample sizes roundwise, fig.height=5, fig.width=14}
trial_n_median <- choices %>% 
  group_by(model, psi, threshold, theta) %>% 
  summarise(median_n = median(n_sample))

trial_n_median %>% 
  filter(model == "roundwise") %>% 
  ggplot(aes(psi, y = median_n, color = threshold)) + 
  facet_wrap(~theta, nrow = 1, labeller = as_labeller(label_theta, label_parsed)) + 
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Median Trial-Level Sample Size", 
       color = "Threshold") + 
  geom_hline(yintercept = 14, linetype = "dashed") + # meta-analytic median
  geom_point(size = 4) +
  geom_line(size = 1) +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8)+ 
  theme_apa()
```

* The trial-level sample sizes increase with **decreasing switching probabilities** and **increasing thresholds**. 

* The trial-level sample sizes indicate some combinations of switching probabilities and thresholds cause **sample sizes to approximate the meta-analytic mean** found by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)).
The respective combinations - i.e., high switching probabilities and high thresholds - were elsewhere (see Hills & Hertwig, [2010](http://journals.sagepub.com/doi/10.1177/0956797610387443)) suggested to relate closely to the roundwise strategy.
In contrast, low (high) switching probabilities and large (small) thresholds produce sample sizes that are considerably larger (smaller) than than the meta-analytic median.

*Note*. Assuming that people make systematic choices - i.e., choices that are based on true differences in the latent properties of choice alternatives - then whatever property is used to assess differences between the options may be accurately inferred with the meta-analytic derived sample size of about 14. 
One might reverse-engineer what property that is depending on the model and parameter combinations.

The following figure shows how small trial-level sample sizes in turn lead to larger deviations of the (trial-level) sampled relative frequencies from the objective probabilities.
Each point represents the median across all trials for the respective objective probability and parameter combination.
The dashed identity line implies a match between the objective probabilities and the trial-level sampled relative frequencies.

```{r trial-level relative frequencies roundwise, fig.height=12}
trial_ep_median <- choices %>% 
  group_by(model, psi, threshold, theta, p_r_high) %>% 
  summarise(median_ep_r_high = median(ep_r_high, na.rm = TRUE))

trial_ep_median %>% 
  filter(model == "roundwise") %>%
  ggplot(aes(p_r_high, y = median_ep_r_high, color = threshold)) + 
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed),
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Objective Probability of the High-Rank Risky Outcome",
       y = "Median Trial-Level Sampled Relative Frequency", 
       color = "Threshold") +
  geom_point() +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", size = 1) + 
  theme_apa()
```

Following from the laws of large numbers, the relative frequencies within a (very) large sample converge almost surely to the objective probabilities.
Thus: 

* **For low switching probabilities, trial-level sampled relative frequencies tend to match the objective probabilities more closely than for high switching probabilities** (vertical grid dimension, read from top to bottom).
Because of the positive skew of their binomial distribution, small-probability outcomes are then more often undersampled than oversampled.
This systematic sampling error caused by frugal sampling is commonly used to explain the as-if underweighting of rare outcomes pattern in decisions from experience (e.g., Hertwig et al., [2004](https://journals.sagepub.com/doi/10.1111/j.0956-7976.2004.00715.x)).

* **For high thresholds, trial-level sampled relative frequencies match the objective probabilities more closely than for low switching probabilities** (horizontal grid dimension, read from left to right). 
Again, because of the positive skew of their binomial distribution, small-probability outcomes are then more often undersampled than oversampled.

The following plot demonstrates that the inverse relationship between switching probabilities and trial-level sample sizes is driven by the inverse relationship between switching probabilities and round-level sample sizes.
Each point represents the median round-level sample sizes across all rounds for the given parameter combination.

```{r eval = FALSE}
simulation_roundwise <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/simulation_roundwise.rds.bz2")
simulation_roundwise <- simulation_roundwise %>% mutate(psi = 1-(psi+.5))
```

```{r round-level sample sizes, eval = FALSE}
round_n_median <- simulation_roundwise %>% 
  group_by(psi, threshold, theta, problem, agent, round) %>% 
  summarise(n_round = n()) %>% 
  group_by(psi, threshold, theta) %>% 
  summarise(median_n_round = median(n_round))

round_n_median %>% 
  ggplot(aes(psi, median_n_round, color = threshold)) +
  facet_wrap(~theta, nrow = 1, labeller = as_labeller(label_theta, label_parsed)) +
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Median Round-Level Sample Size", 
       color = "Threshold") +
  geom_point(size = 4) + 
  geom_line(size = 1) + 
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/round_n_median.png", width = 14, height = 5)
```

```{r fig.height=5, fig.width=14}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/round_n_median.png")
```

* The **round-level sample sizes decrease with increasing switching probabilities**.
Thresholds do not affect the round-level sample size.
However, increasing thresholds naturally lead to a proportional increase of the trial-level sample size.

Because of the inverse relationship between switching probabilities and round-level sample sizes, relative frequencies sampled on the round level can themselves deviate from relative frequencies sampled on the trial level.
The figure below displays their relation.
For each respective parameter combination and relative frequency sampled on the trial level, each point is the median of the frequencies sampled on the round level.
The background represents the underlying density estimation of the trial- and round-level sampled relative frequencies.

```{r relative frequencies round-level, eval = FALSE}

round_ep  <- simulation_roundwise %>% 
  group_by(psi, threshold, theta, problem, agent) %>%
  mutate(n_sample = n(), # total number of single samples
         n_s = sum(is.na(r)), # number of single samples drawn from safe option
         n_r = n_sample - n_s, # number of single samples drawn from risky option
         ep_r_high = round(sum(if_else(r == r_high, 1, 0), na.rm = TRUE)/n_r, 2)) %>% 
  ungroup() %>%
  group_by(psi, threshold, theta, problem, agent, round) %>% 
  mutate(n_round = n(), 
         n_round_s = sum(is.na(r)),
         n_round_r = n_round - n_round_s,
         ep_round_r_high = round(sum(if_else(r == r_high, 1, 0), na.rm = TRUE)/n_round_r, 2)) %>% 
  distinct(psi, threshold, theta, problem, agent, round, ep_r_high, ep_round_r_high) 

round_ep_median <- round_ep %>% 
  group_by(psi, threshold, theta, ep_r_high) %>% 
  summarise(median_ep_round_r_high = median(ep_round_r_high, na.rm = TRUE))

round_ep_median %>% 
  ggplot(aes(x = ep_r_high, y = median_ep_round_r_high, color = threshold)) +  
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed), 
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Trial-Level Sampled Relative Frequency of the High-Rank Risky Outcome",
       y = "Median Round-Level Sampled Relative Frequency",
       color = "Threshold") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  geom_point(size = .8) +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  theme_apa()
  
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/round_ep_median.png", width = 14, height = 12)
```

```{r eval=FALSE}
round_ep_median %>% 
  ggplot(aes(x = ep_r_high, y = median_ep_round_r_high)) + 
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed), 
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Trial-Level Sampled Relative Frequency of the High-Rank Risky Outcome",
       y = "Median Round-Level Sampled Relative Frequency") +
  geom_density2d_filled(data = round_ep, aes(y = ep_round_r_high)) +
  scale_fill_scico_d(palette = "devon") + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "white") + 
  geom_point(size = .5, color = "white") +
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/round_ep_median_density.png", width = 14, height = 12)
```


```{r fig.height=12, fig.width=14}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/round_ep_median.png")
```

* For $\theta = 1$, i.e., when only one mean comparison is carried out, relative frequencies sampled on the round-level are identical to those sampled on the trial level.
For $\theta > 1$, however, increasing switching probabilities cause the relative frequencies sampled on the round-level to decrease and deviate from the relative frequencies sampled on the trial level.
In other words, **with increasing switching probabilities, the round-level samples become less representative of the trial-level sample**.
Because of their positive skew in small samples, **small-probability outcomes tend to be undersampled on the round-level relative to their sampled frequencies on the trial level**. 
This effect is naturally amplified for large thresholds.
In sum, then, for high switching probabilities, small-probability outcomes are expected to contribute to the majority of mean comparisons less than would be warranted by both their latent objective probabilities and their relative frequencies sampled on the trial level. 
Thus, **although sampling error is controlled for on the trial level, the mechanisms of the roundwise model could produce an as-if underweighting of rare outcomes pattern for high switching probabilities**.
**This pattern should in fact become more stable with increasing thresholds and thus trial level sample sizes**.

## Summary integration model

The following figure displays the number of outcomes sampled within choice trials (trial-level sample sizes).
Each point represents the median across all trials for the respective parameter combination.
The dashed horizontal line represents the meta-analytic median reported by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)) for choices between a two-outcome risky prospect and a safe prospect.

```{r trial-level sample sizes summary, fig.height=4}
trial_n_median %>% 
  filter(model == "summary") %>% 
  ggplot(aes(psi, y = median_n)) + 
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed))) + 
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching probability ", psi)),
       y = "Median trial-level sample size",
       color = "Threshold",
       shape = "Threshold") + 
  geom_hline(yintercept = 14, linetype = "dashed") + # meta-analytic median
  geom_point(aes(color = threshold, shape = threshold)) + 
  geom_line(aes(color = threshold)) + 
  scale_color_manual(values = c("#FFACAC", "#919191")) + 
  theme_apa()
```

* For relative thresholds, trial-level sample sizes increase with switching probabilities.
This effect is caused by **random temporal imbalances between prospects for small switching probabilities** that are introduced by the method of implementation, i.e., the use of cumulative sums instead of cumulative means.
Specifically, the evidence accumulation process starts at random on one of the prospects.
This prospects obtains a temporal advantage over the other option because the accumulation of evidence starts sooner. 
The smaller the switching probability, the larger the random temporal advantage.
Vice versa, the higher the switching probability, the smaller the temporal advantage.
These **random temporal imbalances must be taken into account when interpreting the choice data and CPT estimates**

* The **temporal imbalances have severe effects on the number of sampled outcomes for relative thresholds** but not for absolute thresholds.
That is, for absolute thresholds, the number of outcomes that must be sampled from a given option in order to reach a threshold is not affected by the switching probability. 
In contrast, **the lower the switching probability and thus, the larger the temporal imbalances between options, the less outcomes must be sampled from the advantageous prospect for it to reach the relative threshold**.

* For both absolute and relative thresholds, increases in the threshold naturally lead to proportional increases in the total number of samples.

Below, it is shown how the sampled relative frequencies of outcomes match the objective probabilities.

```{r trial-level relative frequencies summary, fig.height=10}
trial_ep_median %>% 
  filter(model == "summary") %>%
  ggplot(aes(p_r_high, y = median_ep_r_high, color = threshold)) + 
  facet_grid(psi~theta, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed), psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
    labs(x = "Objective probability of the high-rank risky outcome",
       y = "Median trial-level sampled relative frequency", 
       color = "Threshold",
       shape = "Threshold") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  geom_point(aes(color = threshold, shape = threshold), size = 1) + 
  scale_color_manual(values = c("#FFACAC", "#919191")) + 
  theme_apa() 
```

* The **sampled relative frequencies match the objective probabilities more closely the higher the thresholds are**. 

* For absolute thresholds, switching probabilities have no effect on the relative sampled frequencies.
However, for relative thresholds, a pattern opposite to that of the roundwise integration model emerges.
That is, **for high switching probabilities, sampled relative frequencies tend to match the objective probabilities more closely** than for low switching probabilities. 
This is because the total number of sampled outcomes increases with increasing switching probabilities.
Again, because of the positive skew of their binomial distribution, small-probability outcomes then tend to be underrepresented rather than overrepresented the majority of times.

# Choice Behavior

In this section, the choice patterns are reported in terms of deviations from EV maximization and sampled mean maximization.
Specifically, for each model and parameter combination, the plots below display the rates of choices that did *not* maximize the latent EV or the sampled mean (false response rates). 
Deviations from sampled mean maximization control for sampling error on the trial level.
The false response rates are reported separately for the existence and rank of the small-probability outcome, because depending on the rank of the small probability outcome, sampled means can either be inflated or deflated.

```{r choice-rates}
# expected value
fr_rates_ev <- choices %>%
  filter(!c(n_s == 0 | n_r == 0)) %>% # drop trials where only one option was attended
  mutate(norm = case_when(ev_ratio > 1 ~ "r", 
                          ev_ratio < 1 ~ "s")) %>% # determine normative choice (ev maximization)
  filter(!is.na(norm)) %>% # drop choice problems without a normative choice
  group_by(model, psi, threshold, theta, rare, norm, choice) %>% 
  summarise(n = n()) %>% 
  mutate(rate = round(n/sum(n), 2)) %>% 
  ungroup() %>%
  complete(model, psi, threshold, theta, rare, norm, choice, fill = list(n = 0, rate = 0)) %>%
  filter(!(model == "roundwise" & theta > 5), !(model == "summary" & theta < 15)) %>% 
  mutate(type = case_when(norm == "r" & choice == "s" ~ "Safe",
                   norm == "s" & choice == "r" ~ "Risky")) %>%
  filter(!is.na(type)) %>% 
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         norm = "EV")


# sampled mean
fr_rates_mean <- choices %>%
  filter(!c(n_s == 0 | n_r == 0)) %>% 
  mutate(norm = case_when(mean_r/safe > 1 ~ "r", 
                          mean_r/safe < 1 ~ "s")) %>% 
  filter(!is.na(norm)) %>% # drop choice problems without a normative choice
  group_by(model, psi, threshold, theta, rare, norm, choice) %>% 
  summarise(n = n()) %>% 
  mutate(rate = round(n/sum(n), 2)) %>% 
  ungroup() %>%
  complete(model, psi, threshold, theta, rare, norm, choice, fill = list(n = 0, rate = 0)) %>%
  filter(!(model == "roundwise" & theta > 5), !(model == "summary" & theta < 15)) %>% 
  mutate(type = case_when(norm == "r" & choice == "s" ~ "Safe",
                          norm == "s" & choice == "r" ~ "Risky")) %>%
  filter(!is.na(type)) %>% 
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         norm = "Mean")

fr_rates <- bind_rows(fr_rates_ev, fr_rates_mean)
```

## Roundwise integration model

```{r choice-rates roundwise, fig.height=10, fig.width=14}
fr_rates_round_r <- fr_rates %>%  filter(model == "roundwise" & threshold == "relative") %>% 
    filter(psi > .9 | psi == .5 | psi == (1-.9)) 

fr_rates %>%
  filter(model == "roundwise" & threshold == "absolute") %>% 
    filter(psi > .9 | psi == .5 | psi == (1-.9)) %>% 
  ggplot(aes(psi, rate)) +
  facet_grid(rare~theta, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed),
                                             theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       linetype = "False Response",
       color = "Norm",
       shape = "Threshold") +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  geom_line(aes(linetype = type, color = norm), size = 1) + 
  geom_point(aes(shape = threshold, color = norm), size = 4) +
  geom_line(data = fr_rates_round_r, aes(linetype = type, color = norm), size = 1) + 
  geom_point(data = fr_rates_round_r, aes(shape = threshold, color = norm), size = 4) +
  scale_color_scico_d(palette = "bam", begin = .2, end = .8) + 
  theme_apa()
```

* The roundwise integration model behaves similar for absolute and relative thresholds.
For small-probability outcomes of high rank, the rates of false safe choices increase with the switching probability, whereas the rates of false risky choices remain low.
Vice versa, for small-probability outcomes of low rank, the rate of false risky choices increases with the switching probability, whereas the rates of false safe choices remain low. 
Both patterns, similar in structure, can be explained by the inverse relationship between the switching probability and sample size and the positive skew of of small-probability outcomes. 
That is, in small samples, small-probability outcomes tend to be undersampled, causing the mean of the risky prospect to be inflated (deflated) if the low (high) rank outcome is of small probability. 
In turn, for inflated (deflated) means, there is a higher chance that the risky prospect is falsely chosen (dismissed) and this chance increases with the switching probability.

* The effect of total sampling error is represented by the divergence of the colored (mean) line from the gray (EV) line:
False response rates tend to be higher if compared to the latent EV instead of the sampled mean, where the latter controls for sampling error.
The sampling error causes the sampled relative frequencies to deviate from the objective probabilities both unsystematically (random random) and systematically (systematic underrepresenation of small probability outcomes).
With increasing thresholds, both error types are reduced as reflected by the convergence of the two lines. 
I.e., the higher the total number of sampled outcomes, the more does the sampled mean converge against the expected value.
The similarity of the curve-pairs demonstrates that the interplay between sampling and integration strategies can have a nuanced and severe effect on the choice behavior beyond sampling error. 

* For choice problems with no small-probability outcomes, false response rates increase with switching probabilities, however, on a low level.
Together with the reversed choice patterns for problems that contain desirable rare outcomes on the one hand and undesirable rare outcomes on the other hand, this shows that the structure of the environment (choice problems) is an important factor.

## Summary integration model

```{r choice-rates summary, fig.height=10, fig.width=14}
fr_rates_summary_r <- fr_rates %>%  
  filter(model == "summary" & threshold == "relative") %>% 
  filter(psi > .9 | psi == .5 | psi == (1-.9)) 
  
fr_rates %>%
  filter(model == "summary" & threshold == "absolute") %>% 
  filter(psi > .9 | psi == .5 | psi == (1-.9)) %>% 
  ggplot(aes(psi, rate)) +
  facet_grid(rare~theta, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed),
                                             theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       linetype = "False Response", 
       color = "Norm",
       shape = "Threshold") +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  geom_line(aes(linetype = type, color = norm), size = 1) + 
  geom_point(aes(shape = threshold, color = norm), size = 4) +
  geom_line(data = fr_rates_summary_r, aes(linetype = type, color = norm), size = 1) + 
  geom_point(data = fr_rates_summary_r, aes(shape = threshold, color = norm), size = 4) +
  scale_color_scico_d(palette = "bam", begin = .2, end = .8) + 
  theme_apa()
```

* In contrast to the roundwise integration model, false response rates decrease with increasing switching probabilities.
Specifically, the false response rates are transitioning from random choice behavior at rates around .5 for low switching probabilities to a systematic maximization of the sampled mean (EV) for high switching probabilities. 
This demonstrates that changes in the sampling strategy do not cause the summary integration model to make systematically different choices.
That is, the mechanisms of the summary integration model are such that evidence is accumulated for differences in the latent EVs, given that approximately the same number of outcomes is sampled from *both* prospects.
The more outcomes are sampled from both prospects, i.e., the higher the thresholds, the more accurately these differences should be assessed. 
Changes on the sampling strategy do not change the latent property for which evidence is accumulated in the summary integration model.
Rather, they affect whether approximately the same number of outcomes is sampled from both prospects or whether one of the prospects, obtains, by chance, a temporal advantage, rendering the decision either systematic or unsystematic, respectively. 

* For small switching probabilities, the effect of sampling error should be overshadowed by the temporal imbalances. 
That is, as no systematic choices are made, deviations from the sampled mean and the latent expected value should be equally random. 
As the switching probability increases, false response rates should be larger for the latent EV than for the sampled mean.
However, as the number of sampled outcomes increases with the switching probabilities, the effect of systematic sampling error is generally low.  

# CPT

In this section, the estimates for the parameters of CPT and the logit choice rule are reported.
Because I am interested in the effects of sampling and integration strategies beyond total sampling error, the sampled relative frequencies are supplied as probability information to CPT's weighting function.

## Roundwise Integration Model

```{r}
cpt_roundwise <- cpt %>% filter(model == "roundwise")
```

### Weighting Function

Below, the parameter estimates of the weighting function ($\gamma, \delta$) and the value function ($\alpha$) as well as their resulting graphical shapes are displayed. 

```{r weighting function roundwise, fig.height=10, fig.width=14}

# gamma estimates

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "gamma", threshold == "relative")

gamma <- cpt_roundwise %>%
  filter(parameter == "gamma", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Curvature  ", gamma)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# delta estimates

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "delta", threshold == "relative")

delta <- cpt_roundwise %>%
  filter(parameter == "delta", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Elevation  ", delta)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# weighting function

weights <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

weights_roundwise <- weights %>% filter(model == "roundwise")
weights_roundwise_relative <- weights_roundwise %>% filter(threshold == "relative")

wf <- weights_roundwise %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(p, w, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Relative Frequency",
       y = expression(paste("Decision Weight  ", pi)),
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(data = weights_roundwise_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

ggarrange(wf, gamma, delta, nrow = 3, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
```

### Value Function

```{r fig.height=7, fig.width=14}

# alpha estimates 

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "alpha", threshold == "relative")

alpha <- cpt_roundwise %>%
  filter(parameter == "alpha", threshold == "absolute") %>% 
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Concavity  ", alpha)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

values <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

values_roundwise <- values %>% filter(model == "roundwise")
values_roundwise_relative <- values_roundwise %>% filter(threshold == "relative")

vf <- values_roundwise %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(x, v, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Outcome",
       y = "Subjective Value",
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 20, 10)) +
  scale_y_continuous(breaks = seq(0, 20, 10)) +
  geom_line(data = values_roundwise_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

ggarrange(vf, alpha, nrow = 2, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
```


* For ($\theta = 1$, $\psi = 1$), the 95%-intervals of the posterior distributions are large.
Here, no relative frequencies other than 0 and 1 are supplied to the weighting function, which explains that the values in between cannot be reliably accounted for.

* For ($\theta = 1$, $\psi < 1$), the estimates imply a linear weighting pattern, i.e., ($\gamma \approx 1, \delta \approx1$). 
This is because only a single mean comparison is carried, therefore causing the roundwise integration strategy to always choose the prospect that produces the larger mean.
This result is well in line with the explanation that if the mind were to infer the latent objective probabilities of outcomes from the sampled relative frequencies and to follow the principle of EV maximization, sampling error can account for any deviations from it.
This is also demonstrated by the false response rates displayed above, where there are no choices for $\theta = 1$ that do not maximize the sampled mean.

* For $\theta > 1$, the curvature parameter $\gamma$ takes values $\geq 1$ which increase with switching probabilities, resulting in a increasingly pronounced S-shaped weighting function.
In other words, the higher the switching probability, the more severe is the underweighting (overweighting) of the high-rank outcome of the risky prospect in CPT, if it is of small (large) probability.
That is, the as-if underweighting of rare outcomes pattern indicated by the final choices (i.e., the false response rates) translates rather directly to an underweighting of small-probability outcomes in CPT.

* The elevation parameter $\delta$ takes values $> 1$, however, the estimates increase slightly with switching probabilities, causing the overweighting of the high-rank outcome of the risky prospect to extend across the mid-point of the probability scale.
*It is open for discussion whether this extension of overweighting beyond the mid-point is theoretically implied by the mechanisms of the round-wise integration model: That is, for high switching probabilities, the model is expected to choose the risky prospect, if the probability of its high-rank outcome is $> .5$. To account for the implied choice behavior, CPT might have to overweight high-rank outcomes with a probability far larger than .5 less severely than high-rank outcomes with a probability only a little larger than .5. Such a pattern is implied for $\delta > 1$.*

* The values of $\alpha$ decrease with increasing switching probabilities, causing the graph of the value function to become increasingly concave.
This indicates that the round-wise integration model ignores most of the outcome information if choices are based on ordinal comparisons of single outcomes rather than of means across larger sets of sampled outcomes.
That is, for high switching probabilities, the round-wise integration model is expected to choose the prospect that produces the higher outcome most of the time, irrespective of the exact magnitude of the difference in the outcomes.

* In sum then, the estimate triplets ($\gamma$, $\delta$, $\alpha)$ of the CPT core show that the choices implied by the potential interplay of different sampling strategies and the round-wise integration strategy can lead to distinct signatures in CPT's weighting and value function.
These signatures cannot be due to total sampling error.

## Summary Integration Model

### Weighting Function

* The estimates for the choice consistency parameter $rho$ tend to be low for small switching probabilities, implying that in these cases the highest model fit is achieved, if a random choice is assumed.
Thus, for small switching probabilities, interpretations of the parameter estimates for the CPT core should be made with great caution (if at all).

* For high switching probabilities, the estimates for the weighting function's $\gamma$ and $\delta$ parameter imply a linear weighting of sampled relative frequencies, i.e., $\gamma \approx 1$ and $\delta \approx 1$.

### Value Function

Moreover, the estimates of $\alpha$ imply no strong compression of outcome information.

## Logit Choice Rule

I start by plotting the estimates for the choice sensitivity parameter $\rho \geq 0$, which indicates how sensible the model-implied choices are regarding the evaluations of the core model.

```{r fig.height=5}

cpt_relative <- cpt %>% filter(parameter == "rho", threshold == "relative")

# rho estimates
cpt %>%
  filter(parameter == "rho", threshold == "absolute") %>%
  ggplot(aes(psi, mean, group = model, color = model, shape = threshold)) + 
  facet_wrap(~theta, nrow = 2, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0,5), breaks = seq(0,5, 2.5)) + 
  labs(x = expression(paste("Switching probability", psi)), 
       y = expression(paste("Choice sensitivity ", rho)),
       color = "Model",
       shape = "Treshold") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point() +
  geom_line() +
  scale_color_scico_d(palette = "berlin") + 
  theme_apa() + 
  geom_errorbar(data = cpt_relative, aes(ymin=`2.5%`, ymax=`97.5%`)) + 
  geom_point(data = cpt_relative) +
  geom_line(data = cpt_relative)
```

* For the **summary integration model**, the estimates of $\rho$ increase with switching probabilities. 
Because $\rho = 0$ indicates that the model-implied choices are insensitive to the evaluations of the core CPT model and thus, random, the estimates fit well with the finding of random temporal imbalances that govern the choices of the summary integration for low switching probabilities.  

* For the **roundwise integration model**, all estimates of $rho$ take values $> 1$, indicating that the choices are not random.
However, the estimates decrease with increasing switching probabilities, indicating a diminishing degree of consistency of the model-implied choices with the evaluations - i.e., the strength of preferences - derived from the core CPT model.
*This may indicate that the degree to which the assumptions of the descriptive CPT model fit the assumptions of the generative roundwise model decreases with increasing switching probabilities*.




