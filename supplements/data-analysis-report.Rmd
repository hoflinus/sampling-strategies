---
title: "Sampling Strategies in DfE"
subtitle: "Data Analysis Report"
author: "Linus Hof"
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
    collapsed: true
    code_folding: hide
    keep_md: true
---

```{r setup}
# set global chunk options
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE,
                      eval = FALSE,
                      fig.width = 14)
```

```{r pkgs}
pacman::p_load(tidyverse,
               scico,
               latex2exp,
               stringr,
               ggpubr,
               papaja)
```

```{r data}
choices <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/choice_data.rds.bz2")
cpt <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/cpt_estimates.rds")
```

# Description

This report covers the data analyses underlying the core results reported in the <!--submitted -->manuscript<!--link document-->.
The analyses comprise of the description and explanation of the sampling and choice behavior exercised by the roundwise and summary integration model and their parameters, as well as their translations into the psychoeconomic functions of cumulative prospect theory (CPT).  

# Core Results

* The interplay of sampling and integration strategies can produce distinct choice patterns in decisions from experience.

* These choice patterns translate into characteristic shapes of CPT's value and weighting function.

* Both choice patterns and their psychoeconomic translations arise in the absence of sampling error. 

* A roundwise integration of sampled outcomes can cause the as-if underweighting of rare outcomes pattern, which becomes more robust with increasing sample sizes.


# Sampling Behavior

In experience-based choices, the sampled information tends to deviate from the latent information because the samples are not infinitely large.
That is, the sampled relative frequencies of outcomes often do not match the objective probabilities. 
This sampling error need not be purely random.
Specifically, the smaller the sample, the more positive the skewness of the binomial distribution of small-probability outcomes.
In such cases, then, the respective outcomes tend to be undersampled rather than oversampled.
This sampling error can produce systematic deviations from expected value (EV) or expected utility (EU) maximization that take the form of an as-if underweighting of rare outcomes pattern (Fox & Hadar, [2006](https://psycnet.apa.org/record/2007-04382-008)).

Given the impact of small samples, this section reports the sample sizes and sampled relative frequencies.
However, the main objective of the analyses is to demonstrate that the interplay of sampling and integration strategies can affect the choice behavior irrespective of the existence or absence of sampling error. 

## Roundwise Integration Model

The following figure displays the number of outcomes sampled within choice trials (trial-level sample sizes), the scale on which sampling error is commonly considered.
Each point represents the median across all trials using the respective parameter combination.
The dashed horizontal line represents the meta-analytic median reported by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)) for choices between a two-outcome risky prospect and a safe prospect.

```{r ggplot setup}
# define functions for assigning facet labels in facet_wrap() and facet_grid()
label_theta <- function(string) {
  TeX(paste("$\\theta=$", string, sep = ""))
  }

label_psi <- function(string) {
  TeX(paste("$\\psi=$", string, sep = "")) #switching probability parameter psi
}

label_rare <- function(string) {
  TeX(paste("$\\p_{High}$", string, sep = "")) #type of rare event
}
```


```{r trial-level sample sizes roundwise}
trial_n_median <- choices %>% 
  group_by(model, psi, threshold, theta) %>% 
  summarise(median_n = median(n_sample))

trial_n_median %>% 
  filter(model == "roundwise") %>% 
  ggplot(aes(psi, y = median_n, color = threshold)) + 
  facet_wrap(~theta, nrow = 1, labeller = as_labeller(label_theta, label_parsed)) + 
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Median Trial-Level Sample Size", 
       color = "Threshold") + 
  geom_hline(yintercept = 14, linetype = "dashed") + # meta-analytic median
  geom_point(size = 4) +
  geom_line(size = 1) +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8)+ 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_n_roundwise.png", width = 14, height = 5)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_n_roundwise.png")
```

* The **trial-level sample sizes increase with decreasing switching probabilities and increasing thresholds**. 

* For some combinations of switching probabilities and thresholds, the **sample sizes approximate the meta-analytic mean** found by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)).
The respective combinations - i.e., high switching probabilities and high thresholds - were elsewhere assumed to relate closely to the roundwise integration strategy (see Hills & Hertwig, [2010](http://journals.sagepub.com/doi/10.1177/0956797610387443)).
In contrast, low (high) switching probabilities and large (small) thresholds produce sample sizes that are considerably larger (smaller) than the meta-analytic median.

*Discussion Note.* 
*Assuming that people make systematic choices based on true differences in the latent properties of the alternatives, then whatever property is used may be accurately inferred with the meta-analytic derived sample size of about 14.* 
*One might reverse-engineer what property that is depending on the model and parameter combinations.*

The following figure shows how small trial-level sample sizes lead to larger deviations of the trial-level sampled relative frequencies from the objective probabilities.
Each point represents the median across all trials for the respective objective probability and parameter combination.

```{r trial-level relative frequencies roundwise}
trial_ep_median <- choices %>% 
  group_by(model, psi, threshold, theta, p_r_high) %>% 
  summarise(median_ep_r_high = median(ep_r_high, na.rm = TRUE))

trial_ep_median %>% 
  filter(model == "roundwise") %>%
  ggplot(aes(p_r_high, y = median_ep_r_high, color = threshold)) + 
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed),
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Objective Probability of the High-Rank Risky Outcome",
       y = "Median Trial-Level Sampled Relative Frequency", 
       color = "Threshold") +
  geom_point() +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", size = 1) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_ep_roundwise.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_ep_roundwise.png")
```


Following from the laws of large numbers, the relative frequencies within a (very) large sample almost surely converge to the objective probabilities.
Thus: 

* **For low switching probabilities, trial-level sampled relative frequencies tend to match the objective probabilities more closely than for high switching probabilities** (vertical grid dimension, read from top to bottom).
Because of the positive skewness of their binomial distribution, small-probability outcomes are then more often undersampled than oversampled.

* **For high thresholds, trial-level sampled relative frequencies match the objective probabilities more closely than for low thresholds** (horizontal grid dimension, read from left to right). 

The following plot demonstrates that the inverse relationship between switching probabilities and trial-level sample sizes is driven by the inverse relationship between switching probabilities and round-level sample sizes---i.e., the number of outcomes sampled within a single comparison round.
Each point represents the median round-level sample sizes across all rounds for the given parameter combination.

```{r}
simulation_roundwise <- read_rds("C:/Users/ge84jux/Projects/sampling-strategies/data/simulation_roundwise.rds.bz2")
simulation_roundwise <- simulation_roundwise %>% mutate(psi = 1-(psi+.5))
```

```{r round-level sample sizes, eval = FALSE}
round_n_median <- simulation_roundwise %>% 
  group_by(psi, threshold, theta, problem, agent, round) %>% 
  summarise(n_round = n()) %>% 
  group_by(psi, threshold, theta) %>% 
  summarise(median_n_round = median(n_round))

round_n_median %>% 
  ggplot(aes(psi, median_n_round, color = threshold)) +
  facet_wrap(~theta, nrow = 1, labeller = as_labeller(label_theta, label_parsed)) +
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Median Round-Level Sample Size", 
       color = "Threshold") +
  geom_point(size = 4) + 
  geom_line(size = 1) + 
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/round_n_roundwise.png", width = 14, height = 5)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/round_n_roundwise.png")
```

* The **round-level sample sizes decrease with increasing switching probabilities**.

* Thresholds do not affect the round-level sample size.
However, increasing thresholds naturally lead to a proportional increase of the trial-level sample size.

The roundwise integration mechanism implies that the relative frequencies sampled on the round level can themselves deviate from the relative frequencies sampled on the trial level.
The figure below displays their relation.

```{r round-level relative frequencies}

round_ep  <- simulation_roundwise %>% 
  group_by(psi, threshold, theta, problem, agent) %>%
  mutate(n_sample = n(), # total number of single samples
         n_s = sum(is.na(r)), # number of single samples drawn from safe option
         n_r = n_sample - n_s, # number of single samples drawn from risky option
         ep_r_high = round(sum(if_else(r == r_high, 1, 0), na.rm = TRUE)/n_r, 2)) %>% 
  ungroup() %>%
  group_by(psi, threshold, theta, problem, agent, round) %>% 
  mutate(n_round = n(), 
         n_round_s = sum(is.na(r)),
         n_round_r = n_round - n_round_s,
         ep_round_r_high = round(sum(if_else(r == r_high, 1, 0), na.rm = TRUE)/n_round_r, 2)) %>% 
  distinct(psi, threshold, theta, problem, agent, round, ep_r_high, ep_round_r_high) 

round_ep_median <- round_ep %>% 
  group_by(psi, threshold, theta, ep_r_high) %>% 
  summarise(median_ep_round_r_high = median(ep_round_r_high, na.rm = TRUE))

round_ep_median %>% 
  ggplot(aes(x = ep_r_high, y = median_ep_round_r_high, color = threshold)) +  
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed), 
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Trial-Level Sampled Relative Frequency of the High-Rank Risky Outcome",
       y = "Median Round-Level Sampled Relative Frequency",
       color = "Threshold") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  geom_point(size = .8) +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  theme_apa()
  
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/round_ep_roundwise.png", width = 14, height = 12)

round_ep_median %>% 
  ggplot(aes(x = ep_r_high, y = median_ep_round_r_high)) + 
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed), 
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Trial-Level Sampled Relative Frequency of the High-Rank Risky Outcome",
       y = "Median Round-Level Sampled Relative Frequency") +
  geom_density2d_filled(data = round_ep, aes(y = ep_round_r_high)) +
  scale_fill_scico_d(palette = "devon") + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "white") + 
  geom_point(size = .5, color = "white") +
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/round_ep_density_roundwise.png", width = 14, height = 12)
```


```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/round_ep_roundwise.png")
```

* For $\theta = 1$---i.e., when only one mean comparison is carried out---the relative frequencies sampled on the round level are necessarily identical to those sampled on the trial level.

* For $\theta > 1$, however, increasing switching probabilities cause the relative frequencies sampled on the round level to deviate from the relative frequencies sampled on the trial level.
In other words, **with increasing switching probabilities and decreasing round-level sample sizes, the round-level samples become less representative of the trial-level sample**.
Because of the positive skewness of their binomial distribution, then, **small-probability outcomes tend to be undersampled on the round-level relative to their sampled frequencies on the trial level**.
This effect is naturally amplified for large thresholds.

* Consequentially, for high switching probabilities, small-probability outcomes are expected to contribute to the majority of the mean comparisons less than would be warranted by both their latent objective probabilities and their relative frequencies sampled on the trial level.
Now, because sampling error is usually controlled for on the trial level, **the mechanisms of the roundwise model can produce an as-if underweighting of rare outcomes pattern, even if sampling error is controlled for**.
**This pattern should in fact become more stable with increasing thresholds and thus increasing trial level sample sizes**.
This prediction is rather different from the common assumption that the as-if underweighting of rare outcomes pattern is due to the small number of outcomes sampled prior the final choice.  

## Summary Integration Model

The following figure displays the trial-level sample sizes for the summary integration model.
Each point represents the median across all trials for the respective parameter combination.
The dashed horizontal line again represents the meta-analytic median reported by Wulff et al. ([2018](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000115)).
An analysis of the round level is not applicable for the summary integration model.

```{r trial-level sample sizes summary}
trial_n_median %>% 
  filter(model == "summary") %>% 
  ggplot(aes(psi, y = median_n, color = threshold)) + 
  facet_wrap(~theta, nrow = 1, labeller = as_labeller(label_theta, label_parsed)) + 
  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "Median Trial-Level Sample Size", 
       color = "Threshold") + 
  geom_hline(yintercept = 14, linetype = "dashed") + # meta-analytic median
  geom_point(size = 4) +
  geom_line(size = 1) +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8)+ 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_n_summary.png", width = 14, height = 5)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_n_summary.png")
```

* For relative thresholds, the trial-level sample sizes increase with switching probabilities.
This effect is caused by **random temporal imbalances between the prospects for small switching probabilities**, which are introduced by the method of implementation (use of cumulative sums rather than cumulative means).
Specifically, the evidence accumulation process---i.e., the sampling and summation of outcomes---starts at random on one of the prospects, providing the starting prospect with a temporal advantage over the other just because its accumulated evidence tends to be based on a larger sample at a given point in time.
The smaller the switching probability, the larger this random temporal advantage.
These **random temporal imbalances must be taken into account when interpreting the choice data and CPT estimates for the summary integration model.**

* The **temporal imbalances have severe effects on the number of sampled outcomes for relative thresholds** but not for absolute thresholds.
This is because, for absolute thresholds, the number of outcomes that must be sampled from a *given* option in order for it to reach a threshold is not affected by the switching probability. 
In contrast, **the lower the switching probability and thus, the larger the temporal imbalances between options, the less outcomes must be sampled from the advantageous prospect for it to reach the relative threshold**.

* For both absolute and relative thresholds, increases in the threshold naturally lead to proportional increases in the total number of samples.

Below, it is shown how the sampled relative frequencies of outcomes match the objective probabilities.

```{r trial-level relative frequencies summary}
trial_ep_median %>% 
  filter(model == "summary") %>%
  ggplot(aes(p_r_high, y = median_ep_r_high, color = threshold)) + 
  facet_grid(psi~theta, 
             labeller = labeller(theta = as_labeller(label_theta, default = label_parsed),
                                 psi = as_labeller(label_psi, default = label_parsed))) +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) + 
  labs(x = "Objective Probability of the High-Rank Risky Outcome",
       y = "Median Trial-Level Sampled Relative Frequency", 
       color = "Threshold") +
  geom_point() +
  scale_color_scico_d(palette = "vik", begin = .2, end = .8) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", size = 1) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_ep_summary.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/trial_ep_summary.png")
```


* The **sampled relative frequencies match the objective probabilities more closely the higher the thresholds are**. 
This is because higher thresholds require larger sample sizes.

* For relative thresholds, a pattern opposite to that of the roundwise integration model emerges.
That is, **for high switching probabilities, sampled relative frequencies tend to match the objective probabilities more closely** than for low switching probabilities. 
This is because the total number of sampled outcomes decreases with switching probabilities and vice versa.
Again, because of the positive skewness of their binomial distribution, small-probability outcomes then tend to be underrepresented rather than overrepresented the majority of times.

* For absolute thresholds, switching probabilities have no effect on the relative sampled frequencies.

# Choice Behavior

In this section, the choice patterns produced by the models and parameter combinations are reported in terms of deviations from EV maximization and sampled mean maximization.
Specifically, for each model and parameter combination, the plots below display the rates of choices that did *not* maximize the latent EV or the sampled mean (false response rates).
Deviations from sampled mean maximization control for sampling error on the trial level because the sampled means take all sampled information into account but not more.
If the sampled information deviates from the latent information, this is reflected in deviations of the sampled mean from the latent EV.

The false response rates are reported separately for the existence and rank of the small-probability outcome of the risky prospect and for the type of the false response (false risky or false safe).
This is because, depending on the rank of the small-probability outcome, sampled means of the risky prospect on the trial level (round level) can either be inflated or deflated in or against the direction of the differences in the latent EV (sampled means on the trial level).
Whereas inflation and deflation in the direction of the EV and trial-level mean difference should produce choice patterns consistent with maximization, inflation and deflation in the opposite direction should produce inconsistent choice patterns and thus higher false response rates. 

```{r choice-rates}

# expected value
fr_rates_ev <- choices %>%
  filter(!c(n_s == 0 | n_r == 0)) %>% # drop trials where only one option was attended
  mutate(norm = case_when(ev_ratio > 1 ~ "r", 
                          ev_ratio < 1 ~ "s")) %>% # determine normative choice (ev maximization)
  filter(!is.na(norm)) %>% # drop choice problems without a normative choice
  group_by(model, psi, threshold, theta, rare, norm, choice) %>% 
  summarise(n = n()) %>% 
  mutate(rate = round(n/sum(n), 2)) %>% 
  ungroup() %>%
  complete(model, psi, threshold, theta, rare, norm, choice, fill = list(n = 0, rate = 0)) %>%
  filter(!(model == "roundwise" & theta > 5), !(model == "summary" & theta < 15)) %>% 
  mutate(type = case_when(norm == "r" & choice == "s" ~ "Safe",
                   norm == "s" & choice == "r" ~ "Risky")) %>%
  filter(!is.na(type)) %>% 
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         norm = "EV")


# sampled mean
fr_rates_mean <- choices %>%
  filter(!c(n_s == 0 | n_r == 0)) %>% 
  mutate(norm = case_when(mean_r/safe > 1 ~ "r", 
                          mean_r/safe < 1 ~ "s")) %>% 
  filter(!is.na(norm)) %>% # drop choice problems without a normative choice
  group_by(model, psi, threshold, theta, rare, norm, choice) %>% 
  summarise(n = n()) %>% 
  mutate(rate = round(n/sum(n), 2)) %>% 
  ungroup() %>%
  complete(model, psi, threshold, theta, rare, norm, choice, fill = list(n = 0, rate = 0)) %>%
  filter(!(model == "roundwise" & theta > 5), !(model == "summary" & theta < 15)) %>% 
  mutate(type = case_when(norm == "r" & choice == "s" ~ "Safe",
                          norm == "s" & choice == "r" ~ "Risky")) %>%
  filter(!is.na(type)) %>% 
  select(-c(norm, choice, n)) %>% 
  mutate(rare = case_when(rare == "none" ~ "\\in \\[.2,.8\\]", #change facet labels for rare events
                          rare == "attractive" ~ "\\in (0,.2)",
                          rare == "unattractive" ~ "\\in (.8,1)"),
         norm = "Mean")

fr_rates <- bind_rows(fr_rates_ev, fr_rates_mean)
```

## Roundwise Integration Model

```{r choice-rates roundwise}
fr_rates_round_r <- fr_rates %>%  filter(model == "roundwise" & threshold == "relative") %>% 
    filter(psi > .9 | psi == .5 | psi == (1-.9)) 

fr_rates %>%
  filter(model == "roundwise" & threshold == "absolute") %>% 
    filter(psi > .9 | psi == .5 | psi == (1-.9)) %>% 
  ggplot(aes(psi, rate)) +
  facet_grid(rare~theta, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed),
                                             theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       linetype = "False Response",
       color = "Norm",
       shape = "Threshold") +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  geom_line(aes(linetype = type, color = norm), size = 1) + 
  geom_point(aes(shape = threshold, color = norm), size = 4) +
  geom_line(data = fr_rates_round_r, aes(linetype = type, color = norm), size = 1) + 
  geom_point(data = fr_rates_round_r, aes(shape = threshold, color = norm), size = 4) +
  scale_color_scico_d(palette = "bam", begin = .2, end = .8) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/choice_rates_roundwise.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/choice_rates_roundwise.png")
```

* For **small-probability outcomes of low rank, the rates of false risky choices increase with the switching probability**, whereas the rates of false safe choices remain low (top row).
Vice versa, for **small-probability outcomes of high rank, the rates of false safe choices increase with the switching probability**, whereas the rates of false risky choices remain low (middle row). 

* Both patterns, similar in structure, can be explained by the inverse relationship between switching probabilities and round-level sample sizes, the positive skewness of small-probability outcomes in small samples, and the independence of comparison rounds.
That is, **for high switching probabilities, small-probability outcomes tend to be undersampled within each comparison round, causing the respective outcome to contribute less to the majority of the mean comparisons than would be warranted by both its objective probability and the sampled relative frequency on the trial level**. 
In other words, if the low (high) rank outcome is of low probability, the mean of the risky prospect tends to be inflated (deflated) compared to the latent EV and the trial-level mean in the majority of comparison rounds.
Because each mean comparison is independent and weighted equally, there is, in turn, a higher chance that the risky prospect is falsely chosen (dismissed) and this chance increases with switching probabilities and thresholds.

* The effect of total sampling error is represented by the color coding.
**False response rates tend to be higher if compared to latent EV maximization instead of the sampled mean maximization**, where the latter controls for sampling error.
Sampling error causes the sampled relative frequencies to deviate from the objective probabilities both unsystematically (random random) and systematically (systematic underrepresenation of small probability outcomes).
With **increasing thresholds and thus an increasing number of sampled outcomes, sampling error is reduced as is reflected by the convergence of the two EV and mean lines**. 
The similarity of the curve-pairs demonstrates that **the interplay between sampling and integration strategies can have a nuanced and severe effect on the choice behavior beyond sampling error**. 

* For choice problems with no small-probability outcomes, false response rates increase with switching probabilities, however, on a lower level.
Together with the reversed choice patterns for problems that contain desirable rare outcomes on the one hand and undesirable rare outcomes on the other hand, this shows that the structure of the environment (choice problems) plays an important role for the roundwise integration model to produce normative or non-normative choice behavior. 

*Discussion Note.*
*How robust are the analyses to changes in the choice problems, e.g., multiple outcomes, mixed prospects, etc.?* 

## Summary Integration Model

```{r choice-rates summary}
fr_rates_summary_r <- fr_rates %>%  
  filter(model == "summary" & threshold == "relative") %>% 
  filter(psi > .9 | psi == .5 | psi == (1-.9)) 
  
fr_rates %>%
  filter(model == "summary" & threshold == "absolute") %>% 
  filter(psi > .9 | psi == .5 | psi == (1-.9)) %>% 
  ggplot(aes(psi, rate)) +
  facet_grid(rare~theta, labeller = labeller(rare = as_labeller(label_rare, default = label_parsed),
                                             theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  labs(x = expression(paste("Switching Probability ", psi)),
       y = "False Response Rate",
       linetype = "False Response", 
       color = "Norm",
       shape = "Threshold") +
  scale_x_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  scale_y_continuous(limits = c(-.1, 1.1), breaks = seq(0, 1, .5)) +
  geom_line(aes(linetype = type, color = norm), size = 1) + 
  geom_point(aes(shape = threshold, color = norm), size = 4) +
  geom_line(data = fr_rates_summary_r, aes(linetype = type, color = norm), size = 1) + 
  geom_point(data = fr_rates_summary_r, aes(shape = threshold, color = norm), size = 4) +
  scale_color_scico_d(palette = "bam", begin = .2, end = .8) + 
  theme_apa()

ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/choice_rates_summary.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/choice_rates_summary.png")
```

* For relative thresholds, **false response rates are transitioning from random choice behavior at rates around .5 for low switching probabilities to a systematic maximization of the sampled mean (EV) for high switching probabilities**.
This decrease in the false response rates can be explained by diminishing random temporal imbalances and the ability of the summary integration model to approximate the solutions of EV and mean maximization, given that roughly the same large number of outcomes is sampled from *both* prospects.
Specifically, for low switching probabilities, the summary integration model tends to choose the prospect that is, by chance, first sampled from due to the temporal advantage this prospect obtains (i.e., the cumulative sum of the starting prospect is based on a larger sample at most times).
The imbalances diminish with increasing switching probabilities as here cumulative sums are based on roughly the same underlying sample size.
The rates of sampled mean and EV maximization increase with switching probabilities because the difference in cumulative sums is proportional to the difference in sampled means, given the samples from both prospects are of equal size.
Similar to the sample mean, then, the effect of sampling error should be low for large sample sizes on both prospects, i.e., with high switching probabilities and thresholds.  
**For small switching probabilities, the effect of sampling error is overshadowed by the random temporal imbalances**. 
That is, as no systematic choices are made, deviations from the sampled mean and the latent expected value should be equally random.
Thus, there is no discernible difference in the rates of EV maximization and sampled mean maximization for relative tresholds. 

* For absolute thresholds, 



# CPT and Logit Choice Rule

In this section, the estimates for the parameters of CPT and the logit choice rule are reported.
Because I am interested in the effects of sampling and integration strategies beyond total sampling error, the sampled relative frequencies are supplied as probability information to CPT's weighting function.

## Roundwise Integration Model

```{r}
cpt_roundwise <- cpt %>% filter(model == "roundwise")
```

### Weighting Function

Below, the parameter estimates of the weighting function ($\gamma, \delta$) and the value function ($\alpha$) as well as their resulting graphical shapes are displayed. 

```{r weighting function roundwise}

# gamma estimates

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "gamma", threshold == "relative")

gamma <- cpt_roundwise %>%
  filter(parameter == "gamma", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Curvature  ", gamma)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# delta estimates

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "delta", threshold == "relative")

delta <- cpt_roundwise %>%
  filter(parameter == "delta", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Elevation  ", delta)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# weighting function

weights <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

weights_roundwise <- weights %>% filter(model == "roundwise")
weights_roundwise_relative <- weights_roundwise %>% filter(threshold == "relative")

wf <- weights_roundwise %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(p, w, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Relative Frequency",
       y = expression(paste("Decision Weight  ", pi)),
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(data = weights_roundwise_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

ggarrange(wf, gamma, delta, nrow = 3, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/weighting_function_roundwise.png", width = 14, height = 12)
```

```{r eval=TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/weighting_function_roundwise.png")
```

### Value Function and Logit Choice Rule

```{r value function roundwise}

# alpha estimates 

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "alpha", threshold == "relative")

alpha <- cpt_roundwise %>%
  filter(parameter == "alpha", threshold == "absolute") %>% 
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Concavity  ", alpha)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# value function

values <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

values_roundwise <- values %>% filter(model == "roundwise")
values_roundwise_relative <- values_roundwise %>% filter(threshold == "relative")

vf <- values_roundwise %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(x, v, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Outcome",
       y = "Subjective Value",
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 20, 10)) +
  scale_y_continuous(breaks = seq(0, 20, 10)) +
  geom_line(data = values_roundwise_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

# rho estimates 

cpt_roundwise_relative <- cpt_roundwise %>% filter(parameter == "rho", threshold == "relative")

rho <- cpt_roundwise %>%
  filter(parameter == "rho", threshold == "absolute") %>% 
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0, 5), breaks = seq(0,5,1)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Choice Consistency  ", rho)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_roundwise_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_roundwise_relative, color = "gray") +
  geom_line(data = cpt_roundwise_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

ggarrange(vf, alpha, rho, nrow = 3, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/value_function_roundwise.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/value_function_roundwise.png")
```


* For ($\theta = 1$, $\psi = 1$), the 95%-intervals of the posterior distributions are large.
Here, no relative frequencies other than 0 and 1 are supplied to the weighting function, which explains that the values in between cannot be reliably accounted for.

* For ($\theta = 1$, $\psi < 1$), the estimates imply a linear weighting pattern, i.e., ($\gamma \approx 1, \delta \approx1$). 
This is because only a single mean comparison is carried, therefore causing the roundwise integration strategy to always choose the prospect that produces the larger mean.
This result is well in line with the explanation that if the mind were to infer the latent objective probabilities of outcomes from the sampled relative frequencies and to follow the principle of EV maximization, sampling error can account for any deviations from it.
This is also demonstrated by the false response rates displayed above, where there are no choices for $\theta = 1$ that do not maximize the sampled mean.

* For $\theta > 1$, the curvature parameter $\gamma$ takes values $\geq 1$ which increase with switching probabilities, resulting in a increasingly pronounced S-shaped weighting function.
In other words, the higher the switching probability, the more severe is the underweighting (overweighting) of the high-rank outcome of the risky prospect in CPT, if it is of small (large) probability.
That is, the as-if underweighting of rare outcomes pattern indicated by the final choices (i.e., the false response rates) translates rather directly to an underweighting of small-probability outcomes in CPT.

* The elevation parameter $\delta$ takes values $> 1$, however, the estimates increase slightly with switching probabilities, causing the overweighting of the high-rank outcome of the risky prospect to extend across the mid-point of the probability scale.
*It is open for discussion whether this extension of overweighting beyond the mid-point is theoretically implied by the mechanisms of the roundwise integration model: That is, for high switching probabilities, the model is expected to choose the risky prospect, if the probability of its high-rank outcome is $> .5$. To account for the implied choice behavior, CPT might have to overweight high-rank outcomes with a probability far larger than .5 less severely than high-rank outcomes with a probability only a little larger than .5. Such a pattern is implied for $\delta > 1$.*

* The values of $\alpha$ decrease with increasing switching probabilities, causing the graph of the value function to become increasingly concave.
This indicates that the round-wise integration model ignores most of the outcome information if choices are based on ordinal comparisons of single outcomes rather than of means across larger sets of sampled outcomes.
That is, for high switching probabilities, the round-wise integration model is expected to choose the prospect that produces the higher outcome most of the time, irrespective of the exact magnitude of the difference in the outcomes.

* In sum then, the estimate triplets ($\gamma$, $\delta$, $\alpha)$ of the CPT core show that the choices implied by the potential interplay of different sampling strategies and the roundwise integration strategy can lead to distinct signatures in CPT's weighting and value function.
These signatures cannot be due to total sampling error.

## Summary Integration Model

```{r}
cpt_summary <- cpt %>% filter(model == "summary")
```

### Weighting Function

```{r weighting function summary}

# gamma estimates

cpt_summary_relative <- cpt_summary %>% filter(parameter == "gamma", threshold == "relative")

gamma <- cpt_summary %>%
  filter(parameter == "gamma", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Curvature  ", gamma)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_summary_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_summary_relative, color = "gray") +
  geom_line(data = cpt_summary_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# delta estimates

cpt_summary_relative <- cpt_summary %>% filter(parameter == "delta", threshold == "relative")

delta <- cpt_summary %>%
  filter(parameter == "delta", threshold == "absolute") %>%
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Elevation  ", delta)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_summary_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_summary_relative, color = "gray") +
  geom_line(data = cpt_summary_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# weighting function

weights <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(alpha, rho)) %>%
  expand_grid(p = seq(0, 1, .05)) %>%
  mutate(w = round(  (delta * p^gamma)/ ((delta * p^gamma)+(1-p)^gamma), 2))

weights_summary <- weights %>% filter(model == "summary")
weights_summary_relative <- weights_summary %>% filter(threshold == "relative")

wf <- weights_summary %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(p, w, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Relative Frequency",
       y = expression(paste("Decision Weight  ", pi)),
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 1, .5)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  geom_line(data = weights_summary_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

ggarrange(wf, gamma, delta, nrow = 3, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/weighting_function_summary.png", width = 14, height = 12)
```

```{r eval=TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/weighting_function_summary.png")
```


* The estimates for the choice consistency parameter $rho$ tend to be low for small switching probabilities, implying that in these cases the highest model fit is achieved, if a random choice is assumed.
Thus, for small switching probabilities, interpretations of the parameter estimates for the CPT core should be made with great caution (if at all).

* For high switching probabilities, the estimates for the weighting function's $\gamma$ and $\delta$ parameter imply a linear weighting of sampled relative frequencies, i.e., $\gamma \approx 1$ and $\delta \approx 1$.

### Value Function and Logit Choice Rule 

```{r value function summary}

# alpha estimates 

cpt_summary_relative <- cpt_summary %>% filter(parameter == "alpha", threshold == "relative")

alpha <- cpt_summary %>%
  filter(parameter == "alpha", threshold == "absolute") %>% 
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Concavity  ", alpha)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_summary_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_summary_relative, color = "gray") +
  geom_line(data = cpt_summary_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

# value function

values <- cpt %>%
  select(model, psi, threshold, theta, parameter, mean) %>%
  pivot_wider(names_from = parameter, values_from = mean) %>%
  select(-c(gamma, delta, rho)) %>%
  expand_grid(x = seq(0, 20, .5)) %>%  
  mutate(v = round(x^alpha, 2)) 

values_summary <- values %>% filter(model == "summary")
values_summary_relative <- values_summary %>% filter(threshold == "relative")

vf <- values_summary %>% 
  filter(threshold == "absolute") %>% 
  ggplot(aes(x, v, group = psi, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") + 
  labs(x = "Sampled Outcome",
       y = "Subjective Value",
       color = expression(psi)) +
  scale_x_continuous(breaks = seq(0, 20, 10)) +
  scale_y_continuous(breaks = seq(0, 20, 10)) +
  geom_line(data = values_summary_relative, color = "gray") + 
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) +
  theme_apa()

# rho estimates 

cpt_summary_relative <- cpt_summary %>% filter(parameter == "rho", threshold == "relative")

rho <- cpt_summary %>%
  filter(parameter == "rho", threshold == "absolute") %>% 
  ggplot(aes(psi, mean, color = psi)) +
  facet_wrap(~theta, nrow = 1, labeller = labeller(theta = as_labeller(label_theta, default = label_parsed)), scales = "free") +
  scale_x_continuous(limits = c(0,1.1), breaks = seq(0,1,.5)) + 
  scale_y_continuous(limits = c(0, 5), breaks = seq(0,5,1)) + 
  labs(x = expression(paste("Switching Probability  ", psi)), 
       y = expression(paste("Choice Consistency  ", rho)),
       color = expression(psi)) +
  geom_errorbar(data = cpt_summary_relative, aes(ymin=`2.5%`, ymax=`97.5%`), color = "gray") + 
  geom_point(data = cpt_summary_relative, color = "gray") +
  geom_line(data = cpt_summary_relative, color = "gray") +
  geom_errorbar(aes(ymin=`2.5%`, ymax=`97.5%`), size = 1) + 
  geom_point(size = 3) +
  geom_line(size = 1) +
  scale_color_scico(palette = "tokyo", end = .8) + 
  theme_apa()

ggarrange(vf, alpha, rho, nrow = 3, ncol = 1, common.legend = TRUE, labels = "AUTO", legend = "right")
ggsave(file = "C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/value_function_summary.png", width = 14, height = 12)
```

```{r eval = TRUE}
knitr::include_graphics("C:/Users/ge84jux/Projects/sampling-strategies/supplements/data-analysis-report_files/figures/value_function_roundwise.png")
```

Moreover, the estimates of $\alpha$ imply no strong compression of outcome information.


I start by plotting the estimates for the choice sensitivity parameter $\rho \geq 0$, which indicates how sensible the model-implied choices are regarding the evaluations of the core model.


* For the **summary integration model**, the estimates of $\rho$ increase with switching probabilities. 
Because $\rho = 0$ indicates that the model-implied choices are insensitive to the evaluations of the core CPT model and thus, random, the estimates fit well with the finding of random temporal imbalances that govern the choices of the summary integration for low switching probabilities.  

* For the **summary integration model**, all estimates of $rho$ take values $> 1$, indicating that the choices are not random.
However, the estimates decrease with increasing switching probabilities, indicating a diminishing degree of consistency of the model-implied choices with the evaluations - i.e., the strength of preferences - derived from the core CPT model.
*This may indicate that the degree to which the assumptions of the descriptive CPT model fit the assumptions of the generative summary model decreases with increasing switching probabilities*.


